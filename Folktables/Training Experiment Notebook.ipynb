{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1a2c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/Desktop/Development/CertificationOfDistributionalIF/Folktables/folk_utils.py:976: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[cf] = features[cf].astype(str).astype('category')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw cols: \n",
      "(24000, 23)\n",
      "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23']\n",
      "Raw cols: \n",
      "(6000, 23)\n",
      "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23']\n",
      "DATA SHAPES: \n",
      "(24000, 145)\n",
      "(6000, 145)\n",
      "(6000, 145)\n",
      "****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/sklearn/decomposition/_truncated_svd.py:234: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "sys.path.append('..')\n",
    "\n",
    "#import models\n",
    "import random\n",
    "import numpy as np\n",
    "import FairCertModule\n",
    "from FairCertModule import ACS_categories\n",
    "import folktables\n",
    "from folktables import ACSDataSource, ACSIncome, ACSEmployment\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from FullyConnected import FullyConnected\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "dataset = \"Credit\"\n",
    "\n",
    "# Data loaders\n",
    "import folk_utils\n",
    "if(dataset in [\"Employ\", \"Folk\", \"Insurance\", \"Coverage\"]):\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val, lp_epsilon, sr_epsilon = folk_utils.get_dataset(dataset)\n",
    "    f_epsilon = lp_epsilon\n",
    "elif(dataset in [\"Adult\", \"Credit\", \"German\"]):\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val, lp_epsilon, sr_epsilon = folk_utils.get_UCI_dataset(dataset)\n",
    "    f_epsilon = lp_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cfd7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24000])\n",
      "torch.Size([6000])\n",
      "torch.Size([6000])\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n",
    "print(len(lp_epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0266b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"FAIR-DRO\"\n",
    "\n",
    "if(mode == \"FAIR-GLOB\"):\n",
    "    lr = 0.001 #-10\n",
    "    eps = 1.0\n",
    "    alpha = 0.02#1\n",
    "    bs = 256 \n",
    "    glob_adv = 100\n",
    "if(mode == \"FAIR-IBP\"):\n",
    "    lr = 0.001\n",
    "    eps = 0.02\n",
    "    alpha = 0.02#2\n",
    "    bs = 256 \n",
    "    glob_adv = 0\n",
    "elif(mode == \"FAIR-IBPG\"):\n",
    "    lr = 0.001\n",
    "    eps = 0.075\n",
    "    alpha = 0.02\n",
    "    bs = 256 \n",
    "    glob_adv = 0\n",
    "elif(mode == \"FAIR-PGD\"):\n",
    "    lr = 0.001\n",
    "    eps = 0.02\n",
    "    alpha = 0.02\n",
    "    bs = 256\n",
    "    glob_adv = 0\n",
    "elif(mode == \"FAIR-DRO\"):\n",
    "    lr = 0.001\n",
    "    eps = 0.02\n",
    "    alpha = 0.02\n",
    "    bs = 256\n",
    "    glob_adv = 16\n",
    "elif(mode == \"SGD\"):\n",
    "    lr = 0.001\n",
    "    eps = 0.00\n",
    "    alpha = 0.0\n",
    "    bs = 128\n",
    "    glob_adv = 0\n",
    "if(dataset == \"German\" and mode != \"SGD\"):\n",
    "    alpha = 1.5\n",
    "    eps *= 6\n",
    "    #eps *= 3.5 \n",
    "class custDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.Tensor(X).float()\n",
    "        self.y = y\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "\n",
    "CustTrain = custDataset(X_train, y_train)  \n",
    "CustVal = custDataset(X_val, y_val) \n",
    "CustTest = custDataset(X_val, y_val)\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train, val, test, batch_size=bs):\n",
    "        super().__init__()\n",
    "        self.train_data = train\n",
    "        self.val_data = val\n",
    "        self.test_data = test\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "    \n",
    "dm = CustomDataModule(CustTrain, CustVal, CustVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7777c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.86 2.97 2.79 2.28 2.06 1.72 1.74 0.31 0.08 0.47 0.39 0.3  0.46 2.3\n",
      " 2.87 2.02 2.1  1.96 1.61 0.19 1.15 1.51 0.66 2.79 2.06 1.97 2.03 2.\n",
      " 0.84 0.88 1.02 1.05 0.94 0.36 1.38 1.82 0.89 0.37 1.07 0.84 0.94 2.38\n",
      " 2.38 0.4  0.67 3.17 3.53 2.36 2.7  1.11 1.43 1.65 0.53 0.36 0.25 0.34\n",
      " 0.94 0.81 0.51 0.27 0.93 1.77 0.84 0.61 0.69 0.75 0.1  0.77 0.98 0.81\n",
      " 0.98 0.57 2.09 0.72 1.39 1.14 0.96 1.33 1.85 0.67 2.19 1.32 1.4  0.7\n",
      " 0.94 1.42 0.89 0.91 1.12 1.13 0.87 0.5  0.11 0.06 0.52 0.16 0.23 0.43\n",
      " 0.52 0.66 1.93 4.38 2.07 0.51 1.57 2.18 1.46 1.4  0.55 0.32 0.59 2.79\n",
      " 4.54 2.72 0.63 2.86 1.15 1.88 0.9  0.71 0.59 0.43 2.37 4.36 2.66 0.94\n",
      " 2.42 1.98 1.18 0.46 0.46 0.89 0.94 2.56 3.48 2.47 0.66 2.05 2.57 1.44\n",
      " 0.8  0.32 1.51 0.94]\n",
      "144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.round(lp_epsilon, 2))\n",
    "print(len(lp_epsilon))\n",
    "print()\n",
    "#print(np.round(sr_epsilon, 2))\n",
    "\n",
    "#print(np.round(ex_epsilon, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08d7c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | lays | ModuleList | 4.5 M \n",
      "1 | l1   | Linear     | 296 K \n",
      "2 | lf   | Linear     | 4.1 K \n",
      "------------------------------------\n",
      "4.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 M     Total params\n",
      "17.990    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e756c695ec41ef81561aac1094ccb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated eps:  0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841219b05474464985eca764e0032aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7804362177848816     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7804362177848816    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "if(mode == \"FAIR-GLOB\" or mode == \"FAIR-IBPG\"):\n",
    "    mode_id = \"FAIR-IBP\"\n",
    "else:\n",
    "    mode_id = mode\n",
    "    \n",
    "if(dataset == \"Coverage\"):\n",
    "    lr *= 2\n",
    "DEPTH = 2\n",
    "WIDTH = 2048\n",
    "#model = FullyConnected(hidden_lay=2, hidden_dim=256,\n",
    "model = FullyConnected(hidden_lay=DEPTH, hidden_dim=WIDTH,\n",
    "                       learning_rate = lr, mode=mode_id, \n",
    "                       epsilon=eps, alpha=alpha,\n",
    "                       glob_advs=glob_adv, dataset=dataset)\n",
    "\n",
    "model.set_fair_interval(lp_epsilon)\n",
    "# used to be 30, 35\n",
    "model.MAX_EPOCHS = 5\n",
    "start = time.time()\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"cpu\", devices=1)\n",
    "trainer.fit(model, datamodule=dm)\n",
    "result = trainer.test(model, datamodule=dm)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e539d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1988.6429069042206\n",
      "Est:  59659.28720712662\n"
     ]
    }
   ],
   "source": [
    "print(\"Time: \", end - start)\n",
    "print(\"Est: \", (end - start)*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49654156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIR-DRO2_2048\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory = \"%sModels\"%(dataset)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "MODEL_ID = mode + \"%s_%s\"%(DEPTH, WIDTH)\n",
    "print(MODEL_ID)\n",
    "\n",
    "trainer.save_checkpoint(\"%s/%s.ckpt\"%(directory, MODEL_ID))\n",
    "torch.save(model.state_dict(), \"%s/%s.pt\"%(directory, MODEL_ID))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c37a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00038952514\n"
     ]
    }
   ],
   "source": [
    "from folk_utils import evaluate_accuracy, evaluate_delta_PGD, evaluate_delta_IBP\n",
    "from folk_utils import compute_DIF_certification\n",
    "lp_epsilon = torch.Tensor(lp_epsilon)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "ibp = evaluate_delta_IBP(model, X_test, y_test, lp_epsilon, 0.025, 2)\n",
    "print(ibp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d79fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwicker/Desktop/Development/CertificationOfDistributionalIF/Folktables/folk_utils.py:626: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1659484744261/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  v = torch.Tensor([f_epsilon.numpy() for i in range(N)]).float()\n",
      "100%|███████████████████████████████████████| 1000/1000 [01:42<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0511191263794899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:38<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1571820080280304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:41<00:00,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15606330335140228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dro1, ibp_trend, vg = compute_DIF_certification(model, lp_epsilon, 0.075, 0.025, X_test, y_test, lr = 0.1, N=200, iters=1000, rettrend=True)\n",
    "print(dro1)\n",
    "dro1, ibp_trend, vg = compute_DIF_certification(model, lp_epsilon, 0.075, 0.025, X_test, y_test, lr = 10, N=200, iters=1000, rettrend=True)\n",
    "print(dro1)\n",
    "dro1, ibp_trend, vg = compute_DIF_certification(model, lp_epsilon, 0.075, 0.025, X_test, y_test, lr = 1000, N=200, iters=1000, rettrend=True)\n",
    "print(dro1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f83d985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▎                                  | 132/1000 [00:13<01:27,  9.96it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/wk/dw_2kpzx6yggmhdyw5k5gj200000gn/T/ipykernel_23236/2165531218.py\", line 2, in <module>\n",
      "    dro1, ibp_trend = compute_DIF_falsification(model, lp_epsilon, 0.075, 0.025, X_test, y_test, lr = 0.1, N=200, iters=1000, rettrend=True)\n",
      "  File \"/Users/matthewwicker/Desktop/Development/CertificationOfDistributionalIF/Folktables/folk_utils.py\", line 717, in compute_DIF_falsification\n",
      "    eps.mean().backward()\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/torch/_tensor.py\", line 396, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 175, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/matthewwicker/opt/anaconda3/envs/FairnessEnv/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/var/folders/wk/dw_2kpzx6yggmhdyw5k5gj200000gn/T/ipykernel_23236/2165531218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfolk_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_DIF_falsification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdro1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mibp_trend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_DIF_falsification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp_epsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.075\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrettrend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdro1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Development/CertificationOfDistributionalIF/Folktables/folk_utils.py\u001b[0m in \u001b[0;36mcompute_DIF_falsification\u001b[0;34m(model, f_epsilon, gamma, delta, X_test, y_test, N, iters, rettrend, rand, lr)\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0meps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2102\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/FairnessEnv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from folk_utils import compute_DIF_falsification\n",
    "dro1, ibp_trend = compute_DIF_falsification(model, lp_epsilon, 0.075, 0.025, X_test, y_test, lr = 0.1, N=200, iters=1000, rettrend=True)\n",
    "print(dro1)\n",
    "dro1, ibp_trend = compute_DIF_falsification(model, lp_epsilon, 0.075, 0.025, X_test, y_test, lr = 10, N=200, iters=1000, rettrend=True)\n",
    "print(dro1)\n",
    "dro1, ibp_trend = compute_DIF_falsification(model, lp_epsilon, 0.075, 0.025, X_test, y_test, lr = 1000, N=200, iters=1000, rettrend=True)\n",
    "print(dro1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801adc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ibp_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FairCertModule import *\n",
    "def global_pgd_ibp(model, vec, eps, npoints=128, iterations=1000, lr=0.1, nclasses=2):\n",
    "    points = torch.randn((npoints, model.in_dim))\n",
    "    points.requires_grad_()\n",
    "    lab = torch.ones((npoints)).long()\n",
    "    vec = torch.Tensor(vec)\n",
    "    for i in range(iterations):\n",
    "        points.requires_grad_()\n",
    "        with torch.enable_grad():\n",
    "            weights = [t for t in model.parameters()]\n",
    "            logit_l, logit_u = interval_bound_forward(model, weights, points, vec, eps)\n",
    "            v1 = torch.nn.functional.one_hot(lab, num_classes=nclasses)\n",
    "            v2 = 1 - torch.nn.functional.one_hot(lab, num_classes=nclasses)\n",
    "            min_logit = torch.add(torch.multiply(v2, logit_u), torch.multiply(v1, logit_l))\n",
    "            max_logit = torch.add(torch.multiply(v1, logit_u), torch.multiply(v2, logit_l))\n",
    "            min_i_softmax = F.softmax(min_logit, dim=-1)\n",
    "            max_i_softmax = F.softmax(max_logit, dim=-1)\n",
    "            delta = torch.abs((max_i_softmax - min_i_softmax))\n",
    "            loss = torch.mean(delta)\n",
    "        grad = torch.autograd.grad(loss, [points])[0]\n",
    "        #print(\"Grad: \", grad)\n",
    "        points = points + (lr *  torch.sign(grad.detach()))\n",
    "        points = torch.clip(points, -2.5, 2.5)\n",
    "    print(torch.mean(delta))\n",
    "    return points\n",
    "\n",
    "global_worst_case = global_pgd_ibp(model, lp_epsilon, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New 2 layer experiments\n",
    "\n",
    "two_layer_widths = [8, 128, 1024, 2048]\n",
    "\n",
    "credit_dro_upper = [0.119, 0.224, 0.241, 0.2560]\n",
    "\n",
    "adult_dro_upper = [0.0325, 0.23517, 0.29682, 0.245]\n",
    "\n",
    "german_dro_upper = [0.03777, 0.2126, 0.6155, 0.8273]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [8, 16, 32, 256, 512, 1024, 2048, 4096]\n",
    "adult_times = [43.011, 47.880, 49.758, 61.686, 70.374, 86.382, 116.154, 178.167] \n",
    "credit_times = [24.720, 25.416, 25.970, 37.228, 44.697, 60.636, 82.659, 126.106] \n",
    "german_times = [2.070, 2.1468, 2.1720, 2.4902, 2.6261, 2.840, 3.6319, 4.9928]\n",
    "\n",
    "adult_dro = [213.914, 226.164, 238.306, 363.283, 465.786, 626.370, 930.686, 1617.153]\n",
    "credit_dro = [164.447, 167.181, 178.785, 284.828, 378.492, 526.416, 833.825, 1456.622]\n",
    "german_dro = [10.8215, 10.200, 10.495, 14.657, 15.446, 18.594, 31.932, 45.786]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [8, 32, 256, 512, 1024]\n",
    "credit_accs = [0.7804, 0.7804, 0.7804, 0.7804]\n",
    "credit_ibps = [0.0018, 0.0013, 0.0012, 0.0012, 0.00026]\n",
    "credit_difs = [0.0233, 0.0232, 0.0158, 0.0141, 0.0021]\n",
    "\n",
    "depths = [1, 2, 3, 4]\n",
    "depth_ibps = [0.0012, 0.0004, 1.1291529e-06, 4.1245717e-06]\n",
    "depth_difs = [0.0158, 0.0567, 0.0855, 0.2583]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657073b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult Results\n",
    "widths = [8, 256, 512, 1024]\n",
    "ibps = [0.00057, 7.5408557e-06, 5.7115263e-05]\n",
    "difs = [0.0318, 0.023, 0.0023, 0.0028]\n",
    "\n",
    "depths = [1, 2, 3, 4]\n",
    "ibps = [9.383e-05, 1.0150286e-05, 1.0150286e-05]\n",
    "difs = [0.0142, 0.2426, 0.4764, 0.822]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b25fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# German results\n",
    "depths = [1,2,3,4]\n",
    "difs = [0.0932, 0.3653, 0.4995, 0.6598]\n",
    "\n",
    "widths = [8, 256, 512, 1024]\n",
    "difs = [0.0994, 0.0552, 0.0282, 0.0234]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
