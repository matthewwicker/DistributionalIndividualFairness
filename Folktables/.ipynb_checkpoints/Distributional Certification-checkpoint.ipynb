{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3eadd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data for different states (unseen)\n",
    "\n",
    "import numpy as np\n",
    "import folktables\n",
    "from folktables import ACSDataSource, ACSIncome\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "sys.path.append('..')\n",
    "import random\n",
    "import models\n",
    "import FairCertModule\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from FullyConnected import FullyConnected\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "TEST_EPSILON = 0.05\n",
    "\n",
    "CustomIncome = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP', 'COW', 'SCHL', 'MAR', 'OCCP', 'POBP', 'WKHP','SEX', #'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group='RAC1P',\n",
    "    preprocess=folktables.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7926c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data_states(year):\n",
    "    data_source = ACSDataSource(survey_year=year, horizon='1-Year', survey='person')\n",
    "    state_X_tests = []\n",
    "    state_y_tests = []\n",
    "    states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "    for state in states:\n",
    "        print(\"Loading for \", state)\n",
    "        state_data = data_source.get_data(states=[state], download=True)\n",
    "        features, labels, _ = CustomIncome.df_to_numpy(state_data)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=42)\n",
    "        #X_test = features; y_test = labels\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        state_X_tests.append(X_test)\n",
    "        state_y_tests.append(y_test)\n",
    "    return state_X_tests, state_y_tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97dd77a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data for different years (unseen)\n",
    "\n",
    "def get_data_years(state):\n",
    "    year_X_tests = []\n",
    "    year_y_tests = []\n",
    "    years = ['2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
    "    for year in years:\n",
    "        try:\n",
    "            data_source = ACSDataSource(survey_year=year, horizon='1-Year', survey='person')\n",
    "            state_data = data_source.get_data(states=[state], download=True)\n",
    "            features, labels, _ = CustomIncome.df_to_numpy(state_data)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=42)\n",
    "            #X_test = features; y_test = labels\n",
    "            scaler = StandardScaler()\n",
    "            scaled_data = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            year_X_tests.append(X_test)\n",
    "            year_y_tests.append(y_test)\n",
    "        except:\n",
    "            pass\n",
    "    return year_X_tests, year_y_tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e37918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in different networks\n",
    "\n",
    "MODEL_STATE  = 'CA'\n",
    "MODEL_YEAR   = '2015'\n",
    "MODEL_WIDTH  = '256'\n",
    "MODEL_METRIC = 'LP'\n",
    "\n",
    "# SGD\n",
    "sgd_id = \"SGD\" #'FCN_s=%s_y=%s_w=%s_f=%s_m=%s'%(MODEL_STATE, MODEL_YEAR, MODEL_WIDTH, \"NONE\", \"NONE\")\n",
    "\n",
    "# Fair-PGD\n",
    "pgd_id = \"FAIR-PGD\" #'FCN_s=%s_y=%s_w=%s_f=%s_m=%s'%(MODEL_STATE, MODEL_YEAR, MODEL_WIDTH, MODEL_METRIC, \"FAIR-PGD\")\n",
    "\n",
    "# Fair-IBP\n",
    "ibp_id = \"FAIR-IBP\" #'FCN_s=%s_y=%s_w=%s_f=%s_m=%s'%(MODEL_STATE, MODEL_YEAR, MODEL_WIDTH, MODEL_METRIC, \"FAIR-IBP\")\n",
    "\n",
    "glob_id = \"FAIR-GLOB\"\n",
    "\n",
    "def load_model_from_id(model_id, width=MODEL_WIDTH):\n",
    "    #model = FullyConnected(hidden_lay=2, hidden_dim=int(MODEL_WIDTH),  learning_rate = 0.001, mode='FAIR-IBP')\n",
    "    model = FullyConnected(hidden_lay=2, hidden_dim=256)\n",
    "    ckpt = torch.load(\"FolkModels/%s.ckpt\"%(model_id))\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    checkpoint = torch.load(\"FolkModels/%s.ckpt\"%(model_id))\n",
    "    model.load_state_dict(torch.load('FolkModels/%s.pt'%(model_id)))\n",
    "    return model\n",
    "\n",
    "sgd_model = load_model_from_id(sgd_id)\n",
    "pgd_model = load_model_from_id(pgd_id)\n",
    "ibp_model = load_model_from_id(ibp_id)\n",
    "glob_model = load_model_from_id(glob_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64645cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2015', horizon='1-Year', survey='person')\n",
    "CustomIncome = folktables.BasicProblem(\n",
    "    features=[\n",
    "        'AGEP', 'COW', 'SCHL', 'MAR', 'OCCP', 'POBP', 'WKHP','SEX', #'RAC1P',\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group='RAC1P',\n",
    "    preprocess=folktables.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")\n",
    "ca_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "features, labels, _ = CustomIncome.df_to_numpy(ca_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test  = y_test.astype(int)\n",
    "\n",
    "f_epsilon = FairCertModule.get_explore_intervals(X_test, y_test, sens_maj_inds=[-1],\n",
    "                                              sens_min_inds=[-1], use_sens=False, eps=1)\n",
    "f_epsilon /= sum(f_epsilon)\n",
    "f_epsilon /= np.median(f_epsilon)\n",
    "    \n",
    "X_test = X_test[:,:-1]\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1f2efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7575)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_accuracy(model, X_test, y_test):\n",
    "    #y_pred = torch.Tensor(model.predict(X_test))\n",
    "    #y_test = torch.Tensor(y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = torch.Tensor(y_pred)\n",
    "    acc = torch.sum(torch.eq(torch.argmax(y_pred, -1), y_test).to(torch.float32)) / len(y_test)\n",
    "    return acc\n",
    "\n",
    "sgd_acc = evaluate_accuracy(sgd_model, X_test, y_test)\n",
    "pgd_acc = evaluate_accuracy(pgd_model, X_test, y_test)\n",
    "ibp_acc = evaluate_accuracy(ibp_model, X_test, y_test)\n",
    "glob_acc = evaluate_accuracy(glob_model, X_test, y_test)\n",
    "\n",
    "print(glob_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93b91463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FairCertModule import * \n",
    "\n",
    "def I(model, inp, lab, vec, eps, nclasses, ret_max=True):\n",
    "    \"\"\"\n",
    "    This class only works for binary classification at the moment. Can be generalized\n",
    "    with a bit of effort modifying the for loop.\n",
    "    \"\"\"\n",
    "    weights = [t for t in model.parameters()]\n",
    "    logit_l, logit_u = interval_bound_forward(model, weights, inp, vec, eps)\n",
    "    worst_delta = 0\n",
    "    v1 = torch.nn.functional.one_hot(lab, num_classes=nclasses)\n",
    "    v2 = 1 - torch.nn.functional.one_hot(lab, num_classes=nclasses)\n",
    "    min_logit = torch.add(torch.multiply(v2, logit_u), torch.multiply(v1, logit_l))\n",
    "    max_logit = torch.add(torch.multiply(v1, logit_u), torch.multiply(v2, logit_l))\n",
    "    min_i_softmax = F.softmax(min_logit, dim=-1)\n",
    "    max_i_softmax = F.softmax(max_logit, dim=-1)\n",
    "    delta = (max_i_softmax - min_i_softmax)\n",
    "    delta = torch.abs(delta)\n",
    "    #if(ret_max):\n",
    "    #    return np.max(np.max(delta, axis=1))\n",
    "    #else:\n",
    "    return torch.mean(delta, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "41d58efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An implimentation of a projected subgradient method \n",
    "for computing the distributional individual fairness\n",
    "certification.\n",
    "\"\"\"\n",
    "from tqdm import trange\n",
    "\n",
    "def compute_DIF_certification(model, f_epsilon, gamma, delta, X_test, y_test, N=1000, iters=500, rettrend=False):\n",
    "    convergence_trend = []\n",
    "    vg = torch.Tensor([[ delta+(l*random.uniform(0, 1)) for i in range(N)]]).T\n",
    "    vg.requires_grad_()\n",
    "    v = torch.Tensor([f_epsilon for i in range(N)]).float()\n",
    "    X = X_test[0:N].float()\n",
    "    y = y_test[0:N].long()\n",
    "    lr = 2.0\n",
    "    lr *= gamma\n",
    "    for i in trange(iters):\n",
    "        vg.requires_grad_()\n",
    "        with torch.enable_grad():\n",
    "            eps = I(model, X, y, v, vg, 2) \n",
    "        eps.mean().backward()\n",
    "        g = vg.grad\n",
    "        vg = vg.detach()\n",
    "        vg = vg + (lr*(g/torch.norm(g)))\n",
    "        n = torch.mean(vg)\n",
    "        if(n > gamma):\n",
    "            vg /= n\n",
    "            vg *= gamma\n",
    "        # n.b. this projection step is sound, but not perhaps as tight as it could be\n",
    "        vg = torch.clip(vg, delta, 1e3) # clipping up any values that shrunk below delta\n",
    "        convergence_trend.append(float(eps.mean()))\n",
    "    if(rettrend):\n",
    "        return eps.mean(), convergence_trend\n",
    "    else:\n",
    "        return eps.mean()\n",
    "\n",
    "#sgd_dif = compute_DIF_certification(sgd_model, f_epsilon, 0.1, 0.05, X_test, y_test)\n",
    "#pgd_dif = compute_DIF_certification(pgd_model, f_epsilon, 0.1, 0.05, X_test, y_test)\n",
    "#ibp_dif = compute_DIF_certification(ibp_model, f_epsilon, 0.1, 0.05, X_test, y_test)\n",
    "#glo_dif = compute_DIF_certification(glob_model, f_epsilon, 0.1, 0.05, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e00ad01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955\n",
      "0.758\n",
      "0.075\n",
      "0.055\n"
     ]
    }
   ],
   "source": [
    "print(np.round(float(sgd_dif), 3))\n",
    "print(np.round(float(pgd_dif), 3))\n",
    "print(np.round(float(ibp_dif), 3))\n",
    "print(np.round(float(glo_dif), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ec78c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [00:08<00:00, 59.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0268, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "def compute_DIF_falsification(model, f_epsilon, gamma, delta, X_test, y_test, N=1000, iters=500, rettrend=False):\n",
    "    convergence_trend = []\n",
    "    vg = torch.Tensor([[ delta for i in range(N)]]).T\n",
    "    vg.requires_grad_()\n",
    "    v = torch.Tensor([f_epsilon for i in range(N)]).float()\n",
    "    X = X_test[0:N].float()\n",
    "    X_orig = copy.deepcopy(X)\n",
    "    y = y_test[0:N].long()\n",
    "    lr = 100.0\n",
    "    lr *= gamma\n",
    "    for i in trange(iters):\n",
    "        X.requires_grad_()\n",
    "        with torch.enable_grad():\n",
    "            eps = I(model, X, y, v, vg, 2) \n",
    "        eps.mean().backward()\n",
    "        g = X.grad\n",
    "        X = X.detach()\n",
    "        X = X + (lr * g) #(lr*(g/torch.norm(g)))\n",
    "        # n.b. this projection step is sound, but not perhaps as tight as it could be\n",
    "        X = torch.clip(X, X_orig - 2*gamma, X_orig + 2*gamma) # clipping up any values that shrunk below delta\n",
    "        convergence_trend.append(float(eps.mean()))\n",
    "    if(rettrend):\n",
    "        return eps.mean(), convergence_trend\n",
    "    else:\n",
    "        return eps.mean()\n",
    "\n",
    "sgd_dif = compute_DIF_falsification(glob_model, f_epsilon, 0.1, 0.05, X_test, y_test)\n",
    "print(sgd_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "814b7cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [00:08<00:00, 61.79it/s]\n",
      "100%|█████████████████████████████████████████| 500/500 [00:08<00:00, 62.32it/s]\n"
     ]
    }
   ],
   "source": [
    "low_dif, lower_converge = compute_DIF_falsification(sgd_model, f_epsilon, 0.1, 0.05, X_test, y_test, rettrend=True)\n",
    "upp_dif, upper_converge = compute_DIF_certification(sgd_model, f_epsilon, 0.1, 0.05, X_test, y_test, rettrend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c338e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14741934835910797\n",
      "0.4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(low_dif)\n",
    "print(upp_dif)\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lower_converge[1:], c='b')\n",
    "plt.plot(upper_converge[1:], c='r')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
